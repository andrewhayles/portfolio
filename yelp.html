<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Page-specific title from the markdown file -->
    <title>Yelp Academic Dataset - Andrew Hayles</title>
    
    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Load custom fonts -->
    <link href="https://fonts.googleapis.com/css2?family=DM+Mono:wght@400;500&family=Inter:wght@400;700&display=swap" rel="stylesheet">
    
    <script>
      // --- Custom Tailwind Config (consistent with index.html) ---
      tailwind.config = {
        darkMode: 'media', 
        theme: {
          extend: {
            fontFamily: {
              sans: ['Inter', 'sans-serif'],
              mono: ['"DM Mono"', 'monospace'],
            },
            colors: {
              light: '#ffffff',
              onLight: '#050806',
              dark: '#000000',
              onDark: '#FBFFF2',
              primary: '#0804F6',
              onPrimary: '#FBFFF2',
              secondary: '#FE491F',
              onSecondary: '#050806',
              complementary: '#565862',
              onComplementary: '#FBFFF2',
            }
          }
        }
      }
    </script>
    
    <style>
      /* --- Prose styling (consistent with index.html) --- */
      .prose { @apply text-onLight dark:text-onDark; }
      .prose h1, .prose h2, .prose h3, .prose h4 { @apply font-mono uppercase font-normal mb-4 mt-8 text-onLight dark:text-onDark; }
      .prose h1 { @apply text-3xl md:text-4xl; }
      .prose h2 { @apply text-2xl md:text-3xl; }
      .prose h3 { @apply text-xl md:text-2xl; }
      .prose h4 { @apply text-lg md:text-xl; }
      .prose p { @apply mb-5 leading-relaxed text-lg; }
      .prose a { @apply text-primary dark:text-secondary hover:underline; }
      .prose img { @apply rounded-lg shadow-md my-6 max-w-full h-auto mx-auto; }
      .prose pre { @apply bg-gray-100 dark:bg-gray-900 text-onLight dark:text-onDark p-4 rounded-lg overflow-x-auto; }
      .prose pre.language-text { @apply bg-gray-50 dark:bg-gray-800 border border-gray-200 dark:border-gray-700; }
      .prose code { @apply font-mono text-sm; }
      .prose blockquote { @apply border-l-4 border-primary dark:border-secondary pl-4 italic my-4; }
      .prose pre code { @apply text-onLight dark:text-onDark; } /* Ensure code text color is correct */
      .prose ul, .prose ol { @apply list-disc list-inside mb-4 pl-4; }
      .prose hr { @apply border-gray-200 dark:border-gray-700 my-8; }
    </style>
</head>

<body class="bg-light dark:bg-dark font-sans text-onLight dark:text-onDark transition-colors duration-300">
  <div class="flex flex-col min-h-screen">

    <!-- === Header (Consistent with index.html) === -->
    <header class="bg-light/95 dark:bg-dark/90 backdrop-blur-sm sticky top-0 z-50 border-b border-gray-200 dark:border-gray-800">
      <nav class="container mx-auto px-4 py-4 flex justify-between items-center">
        <!-- Site Title -->
        <a href="index.html" class="text-xl font-mono uppercase font-bold text-onLight dark:text-onDark hover:text-primary dark:hover:text-secondary">
          Home
        </a>
        
        <!-- Nav Links -->
        <div class="flex items-center space-x-4 md:space-x-6">
          <a href="about.html" class="text-onLight dark:text-onDark hover:text-primary dark:hover:text-secondary font-mono uppercase text-sm font-medium">About</a>
          <a href="https://github.com/andrewhayles/" target="_blank" rel="noopener noreferrer" class="text-onLight dark:text-onDark hover:text-primary dark:hover:text-secondary" aria-label="GitHub">
            <svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M12 2C6.477 2 2 6.477 2 12c0 4.418 2.865 8.165 6.839 9.49.5.092.682-.217.682-.483 0-.237-.009-.868-.013-1.703-2.782.605-3.369-1.343-3.369-1.343-.454-1.158-1.11-1.466-1.11-1.466-.908-.62.069-.608.069-.608 1.003.07 1.531 1.032 1.531 1.032.892 1.53 2.341 1.088 2.91.832.092-.647.35-1.088.636-1.338-2.22-.253-4.555-1.11-4.555-4.951 0-1.093.39-1.988 1.03-2.688-.103-.253-.446-1.272.098-2.65 0 0 .84-.27 2.75 1.026A9.564 9.564 0 0 1 12 6.844c.85.004 1.705.115 2.504.337 1.909-1.296 2.747-1.026 2.747-1.026.546 1.379.202 2.398.1 2.65.64.7 1.028 1.595 1.028 2.688 0 3.848-2.339 4.695-4.566 4.942.359.309.678.92.678 1.856 0 1.338-.012 2.419-.012 2.747 0 .268.18.58.688.482A10.001 10.001 0 0 0 22 12c0-5.523-4.477-10-10-10Z" clip-rule="evenodd" /></svg>
          </a>
        </div>
      </nav>
    </header>

    <!-- === Main Content === -->
    <main class="flex-grow">
      <!-- Using max-w-4xl for a comfortable reading width for articles -->
      <div class="container mx-auto px-4 py-16 md:py-24 max-w-4xl prose">
        
        <!-- Title from frontmatter -->
        <h1>Yelp Academic Dataset</h1>
        
        <!-- Metadata from frontmatter -->
        <p class="text-complementary dark:text-gray-400 text-lg mb-8">
          Published: September 11, 2025
        </p>

        <!-- Main content from markdown body -->
        <p>This project was done as part of a class on Coursera for learning SQL. I learned a lot about the data in this dataset using these methods and became much more comfortable using the SQL query language after having finished this project. The SQL code for creating the original tables, the Python code for importing the data into the tables, and the SQL code for querying the database are all included on this website.</p>
        
        <p>By inspection of the JSON files that can be downloaded here: <a href="https://business.yelp.com/data/resources/open-dataset/" target="_blank" rel="noopener noreferrer">https://business.yelp.com/data/resources/open-dataset/</a> it can be determined what tables are needed and what columns are needed in each of those tables. Upon further inspection it can be determined what are good choices for the primary keys and the foreign keys to ensure data integrity. For example, since each business has one and only one identification for it, that is a good primary key for the business table (that's the definition of a primary key). Since friends also have to be established users, a foreign key for the friends table is the friend ID that refers back to a specific user ID in the users table. Having plenty of interconnections like this ensures that there aren't ghost entries when the data is imported and that if there are, they are identified and can be removed before data analysis begins. Here's a snippet of a JSON file from the original dataset:</p>
        
        <pre><code class="language-json">{"user_id":"2WnXYQFK0hXEoTxPtV2zvg","name":"anonymized","review_count":665,"yelping_since":"2008-07-25 10:41:00","useful":2086,"funny":1010,"cool":1003,"elite":"2009,2010,2011,2012,2013","friends":"LuO3Bn4f3rlhyHIaNfTlnA, j9B4XdHUhDfTKVecyWQgyA, pypZb3V5TXHOnlTj-qLSrw,"fans":52,"average_stars":3.32,"compliment_hot":89,"compliment_more":13,"compliment_profile":10,"compliment_cute":17,"compliment_list":3,"compliment_note":66,"compliment_plain":96,"compliment_cool":119,"compliment_funny":119,"compliment_writer":35,"compliment_photos":18}</code></pre>
        
        <p>As can be seen, this JSON file "users.JSON" is a good candidate for a table, and each one of these variables in quotes followed by a colon is a good candidate for a column. So there is an intuitive data structure built into this particular dataset that allows for smooth transitioning into a SQLite database. This is not guaranteed by any means in a given dataset. This is a very "nice" dataset for SQL analysis.</p>
        
        <p>After careful inspection of the files and careful coding for the SQL tables, I had a good sense of the data and the connections between the tables, and so I was in a good position to create an ERD (Entity-Relationship Diagram) using Microsoft Paint. It looks like this:</p>
        
        <!-- Replaced local image with placeholder -->
        <img src="/images/ERD-project.webp" alt="ERD for Yelp academic dataset" style="max-width: 100%; height: auto;">
        
        <p>The primary purpose of the project was to get a sense of what it meant to be a 5 star business and what it meant to be a 1 star business. To boil down the findings into their essence, I will simply say the best businesses had the highest frequency of positive words in the reviews and the worst businesses had the highest frequency of negative words in their reviews. These words that were analyzed are linked to instrinsic properties of the object to which they are applied. Words like excellence, quality, good, and kind, and words like lousy, poor, nasty, and rude are simple but they are strong differentiators between good businesses and bad businesses.</p>
        
        <p>Statistical significance testing was done to confirm that there was indeed a significant difference in the number of occurrences of these words in the reviews of the best businesses versus the worst businesses based on the total number of reviews (Chi-squared testing). When the negative words appeared in the best business reviews it was virtually always a "false positive" or perhaps better stated to be a false occurrence of a negative word (in other words, they weren't being accused of being the negative word, the negative word was being used in a different context to distinguish the good business from a bad business, so it was not being used in the normal context that it would be applied to an actually bad business). When the positive words were found in the worst business reviews they were also almost always "false positives" or in other words the word "kind" showed up but it was in the context of, for example, "The customer service team was not kind to me." So there was some noise in the data but even with the noise there was a very strongly significant difference in the frequency of the positive words when the best businesses were compared with the worst businesses as determined by their average rating on Yelp.</p>
        
        <p>When the users were analyzed that essentially made the best business on Yelp the best business by writing all the reviews for it, as predicted there was no particular characteristic that was common to all the users. They were all different when the various parameters describing the users were compared, there was no common feature that stood out amongst the different users. This was predictable because a good business is a good business to a person who yelps a lot, and they are a good business to a person who yelps only a little. A good business is a good business to a very popular user, and it is a good business to a user with few friends. A good business is a good business to long-standing Yelp users, and a good business is a good business to very new Yelp users. This study lends credence to the Yelp construct as it confirms that there are instrinsic properties to the highest rated businesses that transcend any distorting features of the user groups who are leaving the reviews. For example it is possible that the best business is only the best business because the people who frequent that business are users on Yelp whose average stars per review is always 5. In other words, they never leave bad reviews. That was not the case though. So there is some definite legitimacy to the best and worst businesses on Yelp. There are some predictable trends and characteristics of these businesses. A visual example of this is the number of occurrences of negative words like lousy, nasty, rude etc. versus the number of stars on Yelp, seen below:</p>
        
        <!-- Replaced local image with placeholder -->
        <img src="/images/negative_word_frequency.webp" alt="Graph of negative words in reviews of various ratings" style="max-width: 100%; height: auto;">
        
        <p>It's amazing how sharp the drop is in negative word occurrences (y-axis) as the rating on Yelp (x-axis) increases. It requires an exponent in the regression model to capture the behavior of this relationship.</p>
        
        <p>One of the most interesting findings during my analysis was that there was a very wide distribution of average rating per business based on zip code (it could be the case that all zip codes had an average rating that was about the same, but this was far from the reality in the data). This confirms a suspicion that the location of a business can be somehow related to the number of stars that business receives for its ratings. The extent to which this is true is astounding. Although deep investigation into this phenomenon was not made, it is something worth further study (for example, determining whether there was a statistically adequate number of businesses per zip code to be making distinctions in the average rating for those zip codes is a question that remains unanswered at this time). Perhaps this finding ties back to the old saying "Location! Location! Location!" in business circles.</p>
        
        <p>Thank you for considering this data analysis on the Yelp academic data set. I hope it was informative and educating to you. If you have any feedback or comments please send me an email at <a href="mailto:andyhayles@gmail.com">andyhayles@gmail.com</a>.</p>

        <!-- 
          This section inserts the code from the 'code:' block in the frontmatter.
        -->
        <h2>Project Code &amp; Scripts</h2>

        <p>This is the first script I wrote in SQL for this particular project. This script creates tables in the SQLite database for each of the indicated tables in the JSON files with a column for each indicated variable that has an object associated with it (whether it be some type of numerical value or a string or a boolean).</p>
<pre><code class="language-sql">-- Table for business data
CREATE TABLE IF NOT EXISTS businesses (
    business_id TEXT PRIMARY KEY,
    name TEXT,
    address TEXT,
    city TEXT,
    state TEXT,
    postal_code TEXT,
    latitude REAL,
    longitude REAL,
    stars REAL,
    review_count INTEGER,
    is_open INTEGER,
    attributes TEXT, -- Storing as a JSON string
    categories TEXT,
    hours TEXT -- Storing as a JSON string
);

-- Table for user data
CREATE TABLE IF NOT EXISTS users (
    user_id TEXT PRIMARY KEY,
    name TEXT,
    review_count INTEGER,
    yelping_since TEXT,
    useful INTEGER,
    funny INTEGER,
    cool INTEGER,
    elite TEXT,
    fans INTEGER,
    average_stars REAL,
    compliment_hot INTEGER,
    compliment_more INTEGER,
    compliment_profile INTEGER,
    compliment_cute INTEGER,
    compliment_list INTEGER,
    compliment_note INTEGER,
    compliment_plain INTEGER,
    compliment_cool INTEGER,
    compliment_funny INTEGER,
    compliment_writer INTEGER,
    compliment_photos INTEGER
);

-- Table to link friends (many-to-many relationship)
CREATE TABLE IF NOT EXISTS friends (
    user_id TEXT,
    friend_id TEXT,
    PRIMARY KEY (user_id, friend_id),
    FOREIGN KEY (user_id) REFERENCES users(user_id),
    FOREIGN KEY (friend_id) REFERENCES users(user_id)
);

-- Table for review data
CREATE TABLE IF NOT EXISTS reviews (
    review_id TEXT PRIMARY KEY,
    user_id TEXT,
    business_id TEXT,
    stars REAL,
    useful INTEGER,
    funny INTEGER,
    cool INTEGER,
    text TEXT,
    date TEXT,
    FOREIGN KEY (user_id) REFERENCES users(user_id),
    FOREIGN KEY (business_id) REFERENCES businesses(business_id)
);

-- Table for tip data
CREATE TABLE IF NOT EXISTS tips (
    tip_id INTEGER PRIMARY KEY AUTOINCREMENT, -- Added a primary key
    user_id TEXT,
    business_id TEXT,
    text TEXT,
    date TEXT,
    compliment_count INTEGER,
    FOREIGN KEY (user_id) REFERENCES users(user_id),
    FOREIGN KEY (business_id) REFERENCES businesses(business_id)
);

-- Table for check-in data
CREATE TABLE IF NOT EXISTS checkins (
    checkin_id INTEGER PRIMARY KEY AUTOINCREMENT, -- Added a primary key
    business_id TEXT,
    date TEXT,
    FOREIGN KEY (business_id) REFERENCES businesses(business_id)
);
</code></pre>

        <p>This is the Python code I used to import the data into the SQLite database tables that I created. As is evident the SQLite3 library was imported into the script first. The script is carefully designed to weed out any ghost entries in the tables, including reviews/tips/checkins by users that are not in the users table, reviews/tips/checkins of businesses that are not in the business table, etc. This ensures data integrity.</p>
<pre><code class="language-python">import sqlite3
import json

# --- Configuration ---
DB_FILE = "yelp.db"
JSON_FILES = {
    'business': 'business.json',
    'review': 'review.json',
    'user': 'user.json',
    'tip': 'tip.json',
    'checkin': 'checkin.json'
}

# --- Database Connection ---
conn = sqlite3.connect(DB_FILE)
cur = conn.cursor()
cur.execute("PRAGMA foreign_keys = ON;")

def process_file(table_name, file_name, valid_users=None, valid_businesses=None):
    """
    Processes a JSON file, with optional validation for user and business IDs.
    """
    print(f"⏳ Processing {file_name} for table '{table_name}'...")
    count = 0
    skipped = 0
    with open(file_name, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                data = json.loads(line)

                # --- VALIDATION STEP ---
                if valid_users and data.get('user_id') not in valid_users:
                    skipped += 1
                    continue
                if valid_businesses and data.get('business_id') not in valid_businesses:
                    skipped += 1
                    continue
                # --- END VALIDATION ---

                # Special handling for certain tables
                if table_name == 'businesses':
                    data['attributes'] = json.dumps(data.get('attributes', {}))
                    data['hours'] = json.dumps(data.get('hours', {}))
                elif table_name == 'users':
                    data.pop('friends', None) # Friends are handled separately
                elif table_name == 'checkins':
                    business_id = data.get('business_id')
                    dates = data.get('date', '').split(', ')
                    checkin_data = [(business_id, date_str) for date_str in dates if date_str]
                    cur.executemany("INSERT OR IGNORE INTO checkins (business_id, date) VALUES (?, ?)", checkin_data)
                    count += len(checkin_data)
                    continue

                columns = ', '.join(data.keys())
                placeholders = ', '.join(['?'] * len(data))
                sql = f"INSERT OR IGIGNORE INTO {table_name} ({columns}) VALUES ({placeholders})"
                cur.execute(sql, list(data.values()))
                count += 1
                
            except (json.JSONDecodeError, KeyError) as e:
                print(f"⚠️ Could not process line: {line.strip()}. Error: {e}")
    conn.commit()
    if skipped > 0:
        print(f"✅ Finished {file_name}. Inserted {count} records. Skipped {skipped} records with invalid foreign keys.")
    else:
        print(f"✅ Finished {file_name}. Inserted {count} records.")

def process_friends(file_name, valid_users):
    """Populate the friends table, validating that both users in a pair exist."""
    print(f"⏳ Processing {file_name} to build friend links...")
    count = 0
    with open(file_name, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                data = json.loads(line)
                user_id = data['user_id']
                friends_list = data.get('friends', 'None').split(', ')
                if friends_list and friends_list[0] != 'None':
                    valid_friends = [(user_id, friend_id) for friend_id in friends_list if friend_id in valid_users]
                    if valid_friends:
                        cur.executemany("INSERT OR IGNORE INTO friends (user_id, friend_id) VALUES (?, ?)", valid_friends)
                        count += len(valid_friends)
            except (json.JSONDecodeError, KeyError) as e:
                print(f"⚠️ Could not process line: {line.strip()}. Error: {e}")
    conn.commit()
    print(f"✅ Finished friend processing. Inserted {count} valid friend links.")

# --- Main Execution ---
if __name__ == "__main__":
    
    # Process businesses and users first, as they are primary tables
    process_file('businesses', JSON_FILES['business'])
    process_file('users', JSON_FILES['user']) # This is now the "Pass 1" for users

    # Load all valid IDs into memory for efficient lookups
    print("\n🧠 Loading all existing IDs into memory for fast validation...")
    cur.execute("SELECT user_id FROM users")
    valid_user_ids = {row[0] for row in cur.fetchall()}
    cur.execute("SELECT business_id FROM businesses")
    valid_business_ids = {row[0] for row in cur.fetchall()}
    print(f"👍 Found {len(valid_user_ids)} users and {len(valid_business_ids)} businesses.\n")
    
    # Now process all the linked data
    process_friends(JSON_FILES['user'], valid_user_ids) # This is "Pass 2" for friends
    process_file('reviews', JSON_FILES['review'], valid_users=valid_user_ids, valid_businesses=valid_business_ids)
    process_file('tips', JSON_FILES['tip'], valid_users=valid_user_ids, valid_businesses=valid_business_ids)
    process_file('checkins', JSON_FILES['checkin'], valid_businesses=valid_business_ids)
    
    print("\n🎉 Database import complete! Your data is in 'yelp.db'.")
    conn.close()
</code></pre>

        <p>This SQL script finds the top 3 businesses that have reviews for them with the highest average stars and highest number of reviews also (they won't be in the top 3 and only have one review)</p>
<pre><code class="language-sql">SELECT b.business_id, b.name, b.review_count, AVG(r.stars)
FROM businesses AS b
LEFT JOIN reviews AS r ON b.business_id = r.business_id
GROUP BY b.business_id
ORDER BY AVG(r.stars) DESC, b.review_count DESC
LIMIT 3
</code></pre>

        <p>This SQL script finds the lowest 3 businesses ranked by average stars given in their reviews with the most number of reviews (they won't be ranked lowest and only have 1 review).</p>
<pre><code class="language-sql">SELECT b.business_id, b.name, b.review_count, AVG(r.stars)
FROM businesses AS b
LEFT JOIN reviews AS r ON b.business_id = r.business_id
GROUP BY b.business_id
ORDER BY AVG(r.stars) ASC, b.review_count DESC
LIMIT 3
</code></pre>

        <p>This SQL code searches the reviews of the three worst businesses (according to Yelp ratings) for positive words</p>
<pre><code class="language-sql">SELECT
    date,
    review_id,
    business_id,
    text
FROM
    reviews
WHERE
    business_id IN ('Snjy6RdQIkwVMLyaq5Lq1A', 'qOL-4ErJkPF154WWg1y_dA', 'vfVN8Xyng39wedBUO8V9HQ')
    AND (
		text LIKE '%amazing%'
        OR text LIKE '%kind%'
        OR text LIKE '%nice%'
        OR text LIKE '%excellent%'
		OR text LIKE '%love%'
    );
</code></pre>

        <p>This SQL code searches the reviews of the top three most popular businesses for positive words</p>
<pre><code class="language-sql">SELECT
	date,
	review_id,
    business_id,
    text
FROM
    reviews
WHERE
    business_id IN ('1RqfozJoosHAsKZhc5PY7w', '-siOxQQcGKtb-04dX0Cxnw', '4-P4Bzqd01YvKX9tp7IGfQ')
    AND (
		text LIKE '%amazing%'
        OR text LIKE '%kind%'
        OR text LIKE '%nice%'
        OR text LIKE '%excellent%'
		OR text LIKE '%love%'
    );
</code></pre>

        <p>This SQL script finds the frequency of negative words for each number of stars for all reviews.</p>
<pre><code class="language-sql">SELECT
	  stars,
    COUNT(review_id)
FROM
    reviews
WHERE
		text LIKE '%awful%'
        OR text LIKE '%terrible%'
        OR text LIKE '%disgusting%'
        OR text LIKE '%lousy%'
		OR text LIKE '%rude%'
GROUP BY 
	stars
</code></pre>

        <p>This SQL code ranks zip codes in descending order by the number of stars they average for their respective businesses.</p>
<pre><code class="language-sql">SELECT
	b.postal_code,
	AVG(r.stars)
FROM businesses b
LEFT JOIN reviews r ON b.business_id = r.business_id
GROUP BY b.postal_code
ORDER BY AVG(r.stars) DESC
</code></pre>

        <p>I spent a lot of time with this and needed some research and help with this (it uses two CTEs and then refers to both for the final calculation), but this script creates a metric for the most improved business by comparing the average rating for the first 30 reviews to the average rating for the most recent 30 reviews.</p>
<pre><code class="language-sql">-- Step 1: Rank every test for each author in two ways (ascending and descending)
WITH RankedStars AS (
  SELECT
    b.business_id,
	b.name,
    r.stars,
	r.date,
    -- Ranks reviews from oldest to newest (1, 2, 3...)
    ROW_NUMBER() OVER(PARTITION BY b.business_id ORDER BY Date ASC) as RankAsc,
    -- Ranks reviews from newest to oldest (1, 2, 3...)
    ROW_NUMBER() OVER(PARTITION BY b.business_id ORDER BY Date DESC) as RankDesc
  FROM
    businesses b
  LEFT JOIN reviews r ON b.business_id = r.business_id
),

-- Step 2: Use the ranks to calculate the average of the first 3 and last 3 scores
BusinessAverages AS (
  SELECT
    business_id,
	name,
    -- Average the stars ONLY IF its ascending rank is 1, 2, or 3
    AVG(CASE WHEN RankAsc &lt;= 30 THEN stars END) AS AvgFirst3,
    -- Average the stars ONLY IF its descending rank is 1, 2, or 3
    AVG(CASE WHEN RankDesc &lt;= 30 THEN stars END) AS AvgLast3
  FROM
    RankedStars
  GROUP BY
    business_id
)

-- Step 3: Select the final data and calculate the improvement metric
SELECT 
  business_id,
  name,
  ROUND(AvgFirst3,4),
  ROUND(AvgLast3,4),
  ROUND((AvgLast3 - AvgFirst3),4) AS Improvement
FROM 
  BusinessAverages
ORDER BY 
  Improvement DESC;
</code></pre>

        <p>This SQL script helps me study the characteristics of the users who reviewed the highest rated business with the most number of reviews on Yelp.</p>
<pre><code class="language-sql">SELECT 
	*
FROM 
	users u
LEFT JOIN 
	reviews r
ON 
	u.user_id = r.user_id
WHERE
	business_id = "1RqfozJoosHAsKZhc5PY7w"
</code></pre>

        <p>This script allows me to view the reviews for the best business on Yelp</p>
<pre><code class="language-sql">SELECT 
  date,
  stars,
  text
FROM 
  reviews
WHERE
	business_id = "RgbpKI14sbP3bQtDDY_rzA"
ORDER BY
	date ASC
</code></pre>

        <p>Those are all the scripts I used for this project.</p>

      </div> <!-- /prose container -->
    </main>

    <!-- === Footer (Consistent with index.html) === -->
    <footer class="bg-gray-100 dark:bg-gray-900 text-complementary dark:text-onComplementary py-12">
      <div class="container mx-auto px-4 text-center">
        <div class="flex justify-center space-x-6 mb-4">
          <a href="mailto:andyhayles@gmail.com" class="hover:text-primary dark:hover:text-secondary">Contact</a>
          <a href="https://github.com/andrewhayles/" target="_blank" rel="noopener noreferrer" class="hover:text-primary dark:hover:text-secondary">GitHub</a>
        </div>
        <!-- Copyright text from config.json -->
        <p class="text-sm">Powered by <a href="https://www.netlify.com/" target="_blank" rel="noopener noreferrer" class="hover:text-primary dark:hover:text-secondary">Netlify</a></p>
        <p class="text-sm">&copy; 2024 Andrew Hayles. All rights reserved.</p>
      </div>
    </footer>

  </div><!-- /flex-col min-h-screen -->
</body>
</html>
